{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "calcNegaPosiScore.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9HXjVL+M0dQLB23Djoayj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JGS2020-012/text_analysis/blob/master/calcNegaPosiScore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uuoswBJIMEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install janome\n",
        "\n",
        "# 必要なライブラリをインポート\n",
        "from janome.tokenizer import Tokenizer\n",
        "from janome.analyzer import Analyzer\n",
        "from janome.charfilter import *\n",
        "from janome.tokenfilter import *\n",
        "import pathlib\n",
        "import pandas as pd \n",
        "\n",
        "# added kamegai\n",
        "import requests \n",
        "import io\n",
        "import csv\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSHRPENT_TyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stop_words():\n",
        "    stop_word_url = \"http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt\"\n",
        "    stop_word_res = requests.get(stop_word_url).content\n",
        "    stop_word_io = io.StringIO(stop_word_res.decode('utf-8'))\n",
        "    stop_words = stop_word_io.read().split('\\n')\n",
        "    return stop_words\n",
        "\n",
        "STOP_WORDS = get_stop_words()\n",
        "\n",
        "def janome_setting():\n",
        "    \"\"\"\n",
        "    janomeのAnalyzerインスタンス生成\n",
        "    （山崎さんのプログラムを拝借）\n",
        "    \"\"\"  \n",
        "    #Unicode正規化・半角記号除去・全角記号除去・＜＞タグ除去・改行除去\n",
        "    char_filters = [UnicodeNormalizeCharFilter('NFKC'),\n",
        "                    RegexReplaceCharFilter('[!/:%#\\$&\\?\\(\\)~\\.=\\+\\-…]+', ''),\n",
        "                    RegexReplaceCharFilter('[『！”＃＄％＆’（）＝～｜‘｛＋＊｝＜＞？＿－＾￥＠「；：」、。・]', ''),\n",
        "                    RegexReplaceCharFilter('<.*?>', ''), \n",
        "                    RegexReplaceCharFilter('[\\n|\\r|\\t]', '')\n",
        "                   ]\n",
        "    #名詞だけ取得・アルファベット小文字化・基本形\n",
        "    token_filters = [\n",
        "                     #POSKeepFilter(['名詞']),\n",
        "                     LowerCaseFilter(),\n",
        "                     ExtractAttributeFilter('base_form')]\n",
        "    #設定からフィルターを作る\n",
        "    a = Analyzer(char_filters=char_filters, token_filters=token_filters)\n",
        "    return a\n",
        "\n",
        "ANALYZER = janome_setting()\n",
        "\n",
        "def before_filter(before_st):\n",
        "    \"\"\"\n",
        "    生成ずみjanomeのAnalyzerを使って、分かち書き\n",
        "    （山崎さんのプログラムを拝借）\n",
        "    \"\"\"  \n",
        "    #文章をanalyzerに掛け処理する\n",
        "    after_st = ANALYZER.analyze(before_st)\n",
        "    \n",
        "    #ストップワードを除去する\n",
        "    #stop_words = []\n",
        "    # modified kamegai\n",
        "    #path = 'Japanese.txt'\n",
        "    #with open(path) as f:\n",
        "    #    stop_words = f.read().split('\\n')\n",
        "    after_st = [x for x in after_st if x not in STOP_WORDS]\n",
        "\n",
        "    return after_st"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwxdlVte8nja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dict(url_file):\n",
        "    \"\"\"\n",
        "    極性表現辞書をロードする。\n",
        "    \"\"\"  \n",
        "    res = requests.get(url_file).content\n",
        "    lists = []\n",
        "    reader = csv.reader(io.StringIO(res.decode('utf-8')), delimiter='\\t')\n",
        "    for row in reader:\n",
        "        #print(reader.line_num,row[0])\n",
        "        lists.append(row)\n",
        "    return lists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9W9ne8vd_ZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 極性表現辞書を基にスコアリングできる状態にする。\n",
        "\n",
        "def get_sentiment_pn_dict():\n",
        "    \"\"\"\n",
        "    日本語評価極性辞書（用言編）\n",
        "           1                  2　\n",
        "    (例) ネガ（評価）\t恩 着せ が まし い\n",
        "    (方針)・1列目のネガ（評価）は-1、ポジ（評価）は1へ変換する。\n",
        "    　    ・2列目は、文字を連結して、形態素解析を行う。\n",
        "    \"\"\"\n",
        "    sentiment_dict = {}\n",
        "    dict_content = load_dict('http://www.cl.ecei.tohoku.ac.jp/resources/sent_lex/wago.121808.pn')\n",
        "    i = 0\n",
        "    for line in dict_content:\n",
        "      score = 0\n",
        "      if line[0] == 'ポジ（経験）':\n",
        "        score = 1\n",
        "      elif line[0] == 'ネガ（経験）':\n",
        "        score = -1\n",
        "      elif line[0] == 'ポジ（評価）':\n",
        "        score = 1\n",
        "      elif line[0] == 'ネガ（評価）':\n",
        "        score = -1\n",
        "      else:\n",
        "        print('error:　{}'.format(line[0]))\n",
        "        sys.exit()\n",
        "      text = line[1].replace(' ','')\n",
        "      text_wakati = ' '.join(before_filter(text))\n",
        "      if len(text_wakati) > 0:\n",
        "        sentiment_dict[text_wakati] = score\n",
        "      #print('{}, {}, {}, {}'.format(score,line[1],text_wakati,len(text_wakati)))\n",
        "      i = i + 1\n",
        "      if i % 1000 == 0:\n",
        "        print('{} line finished!'.format(i))\n",
        "    return sentiment_dict\n",
        "\n",
        "def get_sentiment_trim_dict():\n",
        "    \"\"\"\n",
        "    日本語評価極性辞書（名詞編）\n",
        "       　   1     2      3　\n",
        "    (例) ２か月   e\t  〜である・になる（状態）客観\n",
        "    (方針)・2列目のnは-1、pは1へ変換する。（p:ポジティブ、e:ニュートラル、n:ネガティブ）\n",
        "          ・3列目に・を含む場合は分割し、～を1列目で置換する。\n",
        "    \"\"\"   \n",
        "    dict_content = load_dict('http://www.cl.ecei.tohoku.ac.jp/resources/sent_lex/pn.csv.m3.120408.trim')\n",
        "    # TODO\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AnHkGKUaAhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9931669c-ff99-44d5-e2f4-6fecbbd5c12e"
      },
      "source": [
        "# スコアリング用辞書を取得\n",
        "sentiment_dict = get_sentiment_pn_dict()\n",
        "#print(sentiment_dict)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 line finished!\n",
            "2000 line finished!\n",
            "3000 line finished!\n",
            "4000 line finished!\n",
            "5000 line finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4njyccaOeDhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_score(text, sdict):\n",
        "  # 文字の長い順にソートした極性表現リストを取得\n",
        "  dict_tmp = {}\n",
        "  text_origin = text\n",
        "  for sentiment, score in sdict.items():\n",
        "    dict_tmp[sentiment] = len(sentiment)\n",
        "\n",
        "  sorted_sentiments = []\n",
        "  for item_list in sorted(dict_tmp.items(), key=lambda x:x[1], reverse=True):\n",
        "    sorted_sentiments.append(item_list[0])\n",
        "  #print(sorted_sentiments)\n",
        "\n",
        "  i = 0\n",
        "  score = 0\n",
        "  while i < len(sorted_sentiments):\n",
        "    if sorted_sentiments[i] in text:\n",
        "      matched = sorted_sentiments[i] \n",
        "      score = score + sdict[matched]\n",
        "      # 最初にマッチした極性表現部分をマスク\n",
        "      if sdict[matched] == 1:\n",
        "        text = text.replace(matched,'【+】',1)\n",
        "      elif sdict[matched] == -1:\n",
        "        text = text.replace(matched,'【-】',1)\n",
        "      # 同一の極性表現が存在する可能性があるため、もう一回チェック\n",
        "      i = i - 1\n",
        "      #print('{}, {}, {}, {}, {}'.format(i, score, matched, text_origin, text))\n",
        "    else:\n",
        "      i = i + 1\n",
        "  return (score,text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtvg-0qYXi4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_score(twitter):\n",
        "  twitter_wakati = ' '.join(before_filter(twitter))\n",
        "  score, mask = calc_score(twitter_wakati, sentiment_dict)\n",
        "  return (score, mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYp5ffeR-cBE",
        "colab_type": "code",
        "outputId": "e60e8d75-9699-4865-9bb8-0cedbc93d1c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# テスト\n",
        "twitter = \"LINEpayはなじまない。けど、payカードはなじむと思ったら、やっぱりなじんだ！\"\n",
        "get_score(twitter)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 'linepay は 【-】 けど pay カード は 【+】 と 思う た やっぱり 【+】 だ')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3o5Hn8fc5vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYksvBHarO40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}